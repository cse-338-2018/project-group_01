{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZMRquIyhLGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9bd7958-1c45-4fb8-f988-446b5c576596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FLo5B-b3kYvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfab954c-5bec-4890-caa7-c2edd1ec4b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk, string\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import tqdm\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from transformers import BertTokenizer,  AutoModelForSequenceClassification\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "nltk.download('punkt') # if necessary...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KvrdCqaSktn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e57f28a-63fc-4b53-c5d8-e4ae7baf2737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gmRDy-1ok7UB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fe4504-0691-437e-bfc8-da3c9d43f775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49801, 1)\n"
          ]
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "data_path = \"/content/drive/MyDrive/Data/combined.csv\"\n",
        "df = pd.read_csv(data_path, index_col = 0)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "COTehbHWlqf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "e252a77e-4ad6-4e8b-dc6e-e8eab18b38ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49801, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 abstract\n",
              "0                                                                                                          Transformers have shown great potential in computer vision tasks. A common\\nbelief is their attention-based token mixer module contributes most to their\\ncompetence. However, recent works show the attention-based module in\\ntransformers can be replaced by spatial MLPs and the resulted models still\\nperform quite well. Based on this observation, we hypothesize that the general\\narchitecture of the transformers, instead of the specific token mixer module,\\nis more essential to the model's performance. To verify this, we deliberately\\nreplace the attention module in transformers with an embarrassingly simple\\nspatial pooling operator to conduct only the most basic token mixing.\\nSurprisingly, we observe that the derived model, termed as PoolFormer, achieves\\ncompetitive performance on multiple computer vision tasks. For example, on\\nImageNet-1K, PoolFormer achieves 82.1% top-1 accuracy, surpassing well-tuned\\nvision transformer/MLP-like baselines DeiT-B/ResMLP-B24 by 0.3%/1.1% accuracy\\nwith 35%/52% fewer parameters and 48%/60% fewer MACs. The effectiveness of\\nPoolFormer verifies our hypothesis and urges us to initiate the concept of\\n\"MetaFormer\", a general architecture abstracted from transformers without\\nspecifying the token mixer. Based on the extensive experiments, we argue that\\nMetaFormer is the key player in achieving superior results for recent\\ntransformer and MLP-like models on vision tasks. This work calls for more\\nfuture research dedicated to improving MetaFormer instead of focusing on the\\ntoken mixer modules. Additionally, our proposed PoolFormer could serve as a\\nstarting baseline for future MetaFormer architecture design. Code is available\\nat https://github.com/sail-sg/poolformer\n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 A critical aspect of reliable communication involves the design of codes that\\nallow transmissions to be robustly and computationally efficiently decoded\\nunder noisy conditions. Advances in the design of reliable codes have been\\ndriven by coding theory and have been sporadic. Recently, it is shown that\\nchannel codes that are comparable to modern codes can be learned solely via\\ndeep learning. In particular, Turbo Autoencoder (TURBOAE), introduced by Jiang\\net al., is shown to achieve the reliability of Turbo codes for Additive White\\nGaussian Noise channels. In this paper, we focus on applying the idea of\\nTURBOAE to various practical channels, such as fading channels and chirp noise\\nchannels. We introduce TURBOAE-TI, a novel neural architecture that combines\\nTURBOAE with a trainable interleaver design. We develop a carefully-designed\\ntraining procedure and a novel interleaver penalty function that are crucial in\\nlearning the interleaver and TURBOAE jointly. We demonstrate that TURBOAE-TI\\noutperforms TURBOAE and LTE Turbo codes for several channels of interest. We\\nalso provide interpretation analysis to better understand TURBOAE-TI.\n",
              "2  Point defects are responsible for a wide range of optoelectronic properties\\nin materials, making it crucial to engineer their concentrations for novel\\nmaterials design. However, considering the plethora of defects in co-doped\\nsemiconducting and dielectric materials and the dependence of defect formation\\nenergies on heat treatment parameters, process design based on an experimental\\ntrial and error approach is not an efficient strategy. This makes it necessary\\nto explore computational pathways for predicting defect equilibria during heat\\ntreatments. The accumulated experimental knowledge on defect transformations in\\ndiamond is unparalleled. Therefore, diamond is an excellent material for\\nbenchmarking computational approaches. By considering nitrogen, hydrogen, and\\nsilicon doped diamond as a model system, we have investigated the pressure\\ndependence of defect formation energies and calculated the defect equilibria\\nduring heat treatment of diamond through ab-initio calculations. We have\\nplotted monolithic-Kr\\\"oger-Vink diagrams for various defects, representing\\ndefect concentrations based on process parameters, such as temperature and\\npartial pressure of gases used during heat treatments of diamond. The method\\ndemonstrated predicts the majority of experimental data, such as nitrogen\\naggregation path leading towards the formation of the B center, annealing of\\nthe B, H3, N3, and NVHx centers at ultra high temperatures, the thermal\\nstability of the SiV center, and temperature dependence of NV concentration. We\\ndemonstrate the possibility of designing heat treatments for a wide range of\\nsemiconducting and dielectric materials by using a relatively inexpensive yet\\nrobust first principles approach, significantly accelerating defect engineering\\nand high-throughput novel materials design.\n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                We investigate the electrostrictive response across a ferroelectric phase\\ntransition from first-principles calculations and refute the prevailing view of\\nconstant electrostriction across the ferroelectric phase boundary. We take as a\\ncase study the epitaxial strain-induced transition from para- to\\nferoelectricity of \\ce{KTaO3}. We show that the magnitude of the\\nelectrostriction diverges with the permitivity at the transition, hence\\nexhibiting giant responses through a calculation of both the M and Q\\nelectrostrictive tensors. We explain the origin of this giant electrostrictive\\nresponse in \\ce{KTaO3} using a microscopic decomposition of the\\nelectrostriction coefficients, and use this understanding to propose design\\nrules for the development of future giant electrostrictors for\\nelectromechanical applications. Finally, we introduce a further means to\\ncalculate electrostriction, specific to ferroelectrics, and not yet utilised in\\nthe literature.\n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Institutions in highly regulated domains such as finance and healthcare often\\nhave restrictive rules around data sharing. Federated learning is a distributed\\nlearning framework that enables multi-institutional collaborations on\\ndecentralized data with improved protection for each collaborator's data\\nprivacy. In this paper, we propose a communication-efficient scheme for\\ndecentralized federated learning called ProxyFL, or proxy-based federated\\nlearning. Each participant in ProxyFL maintains two models, a private model,\\nand a publicly shared proxy model designed to protect the participant's\\nprivacy. Proxy models allow efficient information exchange among participants\\nusing the PushSum method without the need of a centralized server. The proposed\\nmethod eliminates a significant limitation of canonical federated learning by\\nallowing model heterogeneity; each participant can have a private model with\\nany architecture. Furthermore, our protocol for communication by proxy leads to\\nstronger privacy guarantees using differential privacy analysis. Experiments on\\npopular image datasets, and a pan-cancer diagnostic problem using over 30,000\\nhigh-quality gigapixel histology whole slide images, show that ProxyFL can\\noutperform existing alternatives with much less communication overhead and\\nstronger privacy."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-497ba1ad-c327-46bc-9a76-c4c696498860\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Transformers have shown great potential in computer vision tasks. A common\\nbelief is their attention-based token mixer module contributes most to their\\ncompetence. However, recent works show the attention-based module in\\ntransformers can be replaced by spatial MLPs and the resulted models still\\nperform quite well. Based on this observation, we hypothesize that the general\\narchitecture of the transformers, instead of the specific token mixer module,\\nis more essential to the model's performance. To verify this, we deliberately\\nreplace the attention module in transformers with an embarrassingly simple\\nspatial pooling operator to conduct only the most basic token mixing.\\nSurprisingly, we observe that the derived model, termed as PoolFormer, achieves\\ncompetitive performance on multiple computer vision tasks. For example, on\\nImageNet-1K, PoolFormer achieves 82.1% top-1 accuracy, surpassing well-tuned\\nvision transformer/MLP-like baselines DeiT-B/ResMLP-B24 by 0.3%/1.1% accuracy\\nwith 35%/52% fewer parameters and 48%/60% fewer MACs. The effectiveness of\\nPoolFormer verifies our hypothesis and urges us to initiate the concept of\\n\"MetaFormer\", a general architecture abstracted from transformers without\\nspecifying the token mixer. Based on the extensive experiments, we argue that\\nMetaFormer is the key player in achieving superior results for recent\\ntransformer and MLP-like models on vision tasks. This work calls for more\\nfuture research dedicated to improving MetaFormer instead of focusing on the\\ntoken mixer modules. Additionally, our proposed PoolFormer could serve as a\\nstarting baseline for future MetaFormer architecture design. Code is available\\nat https://github.com/sail-sg/poolformer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A critical aspect of reliable communication involves the design of codes that\\nallow transmissions to be robustly and computationally efficiently decoded\\nunder noisy conditions. Advances in the design of reliable codes have been\\ndriven by coding theory and have been sporadic. Recently, it is shown that\\nchannel codes that are comparable to modern codes can be learned solely via\\ndeep learning. In particular, Turbo Autoencoder (TURBOAE), introduced by Jiang\\net al., is shown to achieve the reliability of Turbo codes for Additive White\\nGaussian Noise channels. In this paper, we focus on applying the idea of\\nTURBOAE to various practical channels, such as fading channels and chirp noise\\nchannels. We introduce TURBOAE-TI, a novel neural architecture that combines\\nTURBOAE with a trainable interleaver design. We develop a carefully-designed\\ntraining procedure and a novel interleaver penalty function that are crucial in\\nlearning the interleaver and TURBOAE jointly. We demonstrate that TURBOAE-TI\\noutperforms TURBOAE and LTE Turbo codes for several channels of interest. We\\nalso provide interpretation analysis to better understand TURBOAE-TI.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Point defects are responsible for a wide range of optoelectronic properties\\nin materials, making it crucial to engineer their concentrations for novel\\nmaterials design. However, considering the plethora of defects in co-doped\\nsemiconducting and dielectric materials and the dependence of defect formation\\nenergies on heat treatment parameters, process design based on an experimental\\ntrial and error approach is not an efficient strategy. This makes it necessary\\nto explore computational pathways for predicting defect equilibria during heat\\ntreatments. The accumulated experimental knowledge on defect transformations in\\ndiamond is unparalleled. Therefore, diamond is an excellent material for\\nbenchmarking computational approaches. By considering nitrogen, hydrogen, and\\nsilicon doped diamond as a model system, we have investigated the pressure\\ndependence of defect formation energies and calculated the defect equilibria\\nduring heat treatment of diamond through ab-initio calculations. We have\\nplotted monolithic-Kr\\\"oger-Vink diagrams for various defects, representing\\ndefect concentrations based on process parameters, such as temperature and\\npartial pressure of gases used during heat treatments of diamond. The method\\ndemonstrated predicts the majority of experimental data, such as nitrogen\\naggregation path leading towards the formation of the B center, annealing of\\nthe B, H3, N3, and NVHx centers at ultra high temperatures, the thermal\\nstability of the SiV center, and temperature dependence of NV concentration. We\\ndemonstrate the possibility of designing heat treatments for a wide range of\\nsemiconducting and dielectric materials by using a relatively inexpensive yet\\nrobust first principles approach, significantly accelerating defect engineering\\nand high-throughput novel materials design.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We investigate the electrostrictive response across a ferroelectric phase\\ntransition from first-principles calculations and refute the prevailing view of\\nconstant electrostriction across the ferroelectric phase boundary. We take as a\\ncase study the epitaxial strain-induced transition from para- to\\nferoelectricity of \\ce{KTaO3}. We show that the magnitude of the\\nelectrostriction diverges with the permitivity at the transition, hence\\nexhibiting giant responses through a calculation of both the M and Q\\nelectrostrictive tensors. We explain the origin of this giant electrostrictive\\nresponse in \\ce{KTaO3} using a microscopic decomposition of the\\nelectrostriction coefficients, and use this understanding to propose design\\nrules for the development of future giant electrostrictors for\\nelectromechanical applications. Finally, we introduce a further means to\\ncalculate electrostriction, specific to ferroelectrics, and not yet utilised in\\nthe literature.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Institutions in highly regulated domains such as finance and healthcare often\\nhave restrictive rules around data sharing. Federated learning is a distributed\\nlearning framework that enables multi-institutional collaborations on\\ndecentralized data with improved protection for each collaborator's data\\nprivacy. In this paper, we propose a communication-efficient scheme for\\ndecentralized federated learning called ProxyFL, or proxy-based federated\\nlearning. Each participant in ProxyFL maintains two models, a private model,\\nand a publicly shared proxy model designed to protect the participant's\\nprivacy. Proxy models allow efficient information exchange among participants\\nusing the PushSum method without the need of a centralized server. The proposed\\nmethod eliminates a significant limitation of canonical federated learning by\\nallowing model heterogeneity; each participant can have a private model with\\nany architecture. Furthermore, our protocol for communication by proxy leads to\\nstronger privacy guarantees using differential privacy analysis. Experiments on\\npopular image datasets, and a pan-cancer diagnostic problem using over 30,000\\nhigh-quality gigapixel histology whole slide images, show that ProxyFL can\\noutperform existing alternatives with much less communication overhead and\\nstronger privacy.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-497ba1ad-c327-46bc-9a76-c4c696498860')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-497ba1ad-c327-46bc-9a76-c4c696498860 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-497ba1ad-c327-46bc-9a76-c4c696498860');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_data(data_path, sample_size):\n",
        "\n",
        "  # Read the data from specific path\n",
        "  data = pd.read_csv(data_path, index_col=0)\n",
        "  # data = pd.read_csv(data_path, low_memory=False, quoting=3, error_bad_lines=False)\n",
        "\n",
        "  # Drop articles without Abstract\n",
        "  data = data.dropna(subset = ['abstract']).reset_index(drop = True)\n",
        "\n",
        "  # Get \"sample_size\" random articles\n",
        "  # data = data.sample(sample_size)[['abstract']]\n",
        "\n",
        "  return data\n",
        "  \n",
        "source_data = preprocess_data(data_path, 44000)\n",
        "print(source_data.shape)\n",
        "display(source_data.head())\n",
        "#source_data = source_data['abstract'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QLanIGW2lvax"
      },
      "outputs": [],
      "source": [
        "# Initialize the stemmer and tokenizer\n",
        "stemmer = PorterStemmer()\n",
        "tokenizer = word_tokenize\n",
        "# Create a TfidfVectorizer object to convert the text data into numerical features\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Preprocess the text data\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = tokenizer(text)\n",
        "    \n",
        "    # Stem each token\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    \n",
        "    # Join the stemmed tokens back into a single string\n",
        "    stemmed_text = ' '.join(stemmed_tokens)\n",
        "    \n",
        "    return stemmed_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text data of each research paper\n",
        "preprocessed_data = [preprocess_text(text) for text in source_data['abstract'].tolist()]\n",
        "training_data = tfidf.fit_transform(preprocessed_data)\n"
      ],
      "metadata": {
        "id": "NnDqNVsRjvgE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking preprocessed data\n",
        "display(preprocessed_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "xxwd3Lmgj3cT",
        "outputId": "a9712c29-4639-4c0e-e359-e1efcd807be9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[\"transform have shown great potenti in comput vision task . a common belief is their attention-bas token mixer modul contribut most to their compet . howev , recent work show the attention-bas modul in transform can be replac by spatial mlp and the result model still perform quit well . base on thi observ , we hypothes that the gener architectur of the transform , instead of the specif token mixer modul , is more essenti to the model 's perform . to verifi thi , we deliber replac the attent modul in transform with an embarrassingli simpl spatial pool oper to conduct onli the most basic token mix . surprisingli , we observ that the deriv model , term as poolform , achiev competit perform on multipl comput vision task . for exampl , on imagenet-1k , poolform achiev 82.1 % top-1 accuraci , surpass well-tun vision transformer/mlp-lik baselin deit-b/resmlp-b24 by 0.3 % /1.1 % accuraci with 35 % /52 % fewer paramet and 48 % /60 % fewer mac . the effect of poolform verifi our hypothesi and urg us to initi the concept of '' metaform '' , a gener architectur abstract from transform without specifi the token mixer . base on the extens experi , we argu that metaform is the key player in achiev superior result for recent transform and mlp-like model on vision task . thi work call for more futur research dedic to improv metaform instead of focus on the token mixer modul . addit , our propos poolform could serv as a start baselin for futur metaform architectur design . code is avail at http : //github.com/sail-sg/poolform\",\n",
              " 'a critic aspect of reliabl commun involv the design of code that allow transmiss to be robustli and comput effici decod under noisi condit . advanc in the design of reliabl code have been driven by code theori and have been sporad . recent , it is shown that channel code that are compar to modern code can be learn sole via deep learn . in particular , turbo autoencod ( turboa ) , introduc by jiang et al. , is shown to achiev the reliabl of turbo code for addit white gaussian nois channel . in thi paper , we focu on appli the idea of turboa to variou practic channel , such as fade channel and chirp nois channel . we introduc turboae-ti , a novel neural architectur that combin turboa with a trainabl interleav design . we develop a carefully-design train procedur and a novel interleav penalti function that are crucial in learn the interleav and turboa jointli . we demonstr that turboae-ti outperform turboa and lte turbo code for sever channel of interest . we also provid interpret analysi to better understand turboae-ti .',\n",
              " \"point defect are respons for a wide rang of optoelectron properti in materi , make it crucial to engin their concentr for novel materi design . howev , consid the plethora of defect in co-dop semiconduct and dielectr materi and the depend of defect format energi on heat treatment paramet , process design base on an experiment trial and error approach is not an effici strategi . thi make it necessari to explor comput pathway for predict defect equilibria dure heat treatment . the accumul experiment knowledg on defect transform in diamond is unparallel . therefor , diamond is an excel materi for benchmark comput approach . by consid nitrogen , hydrogen , and silicon dope diamond as a model system , we have investig the pressur depend of defect format energi and calcul the defect equilibria dure heat treatment of diamond through ab-initio calcul . we have plot monolithic-kr\\\\ '' oger-vink diagram for variou defect , repres defect concentr base on process paramet , such as temperatur and partial pressur of gase use dure heat treatment of diamond . the method demonstr predict the major of experiment data , such as nitrogen aggreg path lead toward the format of the b center , anneal of the b , h3 , n3 , and nvhx center at ultra high temperatur , the thermal stabil of the siv center , and temperatur depend of nv concentr . we demonstr the possibl of design heat treatment for a wide rang of semiconduct and dielectr materi by use a rel inexpens yet robust first principl approach , significantli acceler defect engin and high-throughput novel materi design .\",\n",
              " 'we investig the electrostrict respons across a ferroelectr phase transit from first-principl calcul and refut the prevail view of constant electrostrict across the ferroelectr phase boundari . we take as a case studi the epitaxi strain-induc transit from para- to feroelectr of \\\\ce { ktao3 } . we show that the magnitud of the electrostrict diverg with the permit at the transit , henc exhibit giant respons through a calcul of both the m and q electrostrict tensor . we explain the origin of thi giant electrostrict respons in \\\\ce { ktao3 } use a microscop decomposit of the electrostrict coeffici , and use thi understand to propos design rule for the develop of futur giant electrostrictor for electromechan applic . final , we introduc a further mean to calcul electrostrict , specif to ferroelectr , and not yet utilis in the literatur .',\n",
              " \"institut in highli regul domain such as financ and healthcar often have restrict rule around data share . feder learn is a distribut learn framework that enabl multi-institut collabor on decentr data with improv protect for each collabor 's data privaci . in thi paper , we propos a communication-effici scheme for decentr feder learn call proxyfl , or proxy-bas feder learn . each particip in proxyfl maintain two model , a privat model , and a publicli share proxi model design to protect the participant' privaci . proxi model allow effici inform exchang among particip use the pushsum method without the need of a central server . the propos method elimin a signific limit of canon feder learn by allow model heterogen ; each particip can have a privat model with ani architectur . furthermor , our protocol for commun by proxi lead to stronger privaci guarante use differenti privaci analysi . experi on popular imag dataset , and a pan-canc diagnost problem use over 30,000 high-qual gigapixel histolog whole slide imag , show that proxyfl can outperform exist altern with much less commun overhead and stronger privaci .\"]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JHMQmTjDHAYK"
      },
      "outputs": [],
      "source": [
        "def process_document(text):\n",
        "    \"\"\"\n",
        "    Create a vector for given text and adjust it for cosine similarity search\n",
        "    \"\"\"\n",
        "    text_vect = create_vector_from_text(tokenizer, model, text)\n",
        "    text_vect = np.array(text_vect)\n",
        "    text_vect = text_vect.reshape(1, -1)\n",
        "\n",
        "    return text_vect\n",
        "\n",
        "def create_vector_from_text(tokenizer, model, text, MAX_LEN = 510):\n",
        "    \n",
        "    input_ids = tokenizer.encode(\n",
        "                        text, \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = MAX_LEN,                           \n",
        "                   )    \n",
        "\n",
        "    results = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\", \n",
        "                              truncating=\"post\", padding=\"post\")\n",
        "    \n",
        "    # Remove the outer list.\n",
        "    input_ids = results[0]\n",
        "\n",
        "    # Create attention masks    \n",
        "    attention_mask = [int(i>0) for i in input_ids]\n",
        "    \n",
        "    # Convert to tensors.\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "    # Add an extra dimension for the \"batch\" (even though there is only one \n",
        "    # input in this batch.)\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    attention_mask = attention_mask.unsqueeze(0)\n",
        "    \n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "    model.eval()\n",
        "    \n",
        "    # Run the text through BERT, and collect all of the hidden states produced\n",
        "    # from all 12 layers. \n",
        "    with torch.no_grad():        \n",
        "        logits, encoded_layers = model(\n",
        "                                    input_ids = input_ids, \n",
        "                                    token_type_ids = None, \n",
        "                                    attention_mask = attention_mask,\n",
        "                                    return_dict=False)\n",
        "\n",
        "    layer_i = 12 # The last BERT layer before the classifier.\n",
        "    batch_i = 0 # Only one input in the batch.\n",
        "    token_i = 0 # The first token, corresponding to [CLS]\n",
        "        \n",
        "    # Extract the embedding.\n",
        "    vector = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "    # Move to the CPU and convert to numpy ndarray.\n",
        "    vector = vector.detach().cpu().numpy()\n",
        "\n",
        "    return(vector)\n",
        "\n",
        "def create_vector_index(data):\n",
        "    \n",
        "    # The list of all the vectors\n",
        "    vectors = []\n",
        "    \n",
        "    # Get overall text data\n",
        "    source_data = data.abstract.values\n",
        "    \n",
        "    # Loop over all the comment and get the embeddings\n",
        "    for text in tqdm(source_data):\n",
        "        \n",
        "        # Get the embedding \n",
        "        vector = create_vector_from_text(tokenizer, model, text)\n",
        "        \n",
        "        #add it to the list\n",
        "        vectors.append(vector)\n",
        "    \n",
        "    data[\"vectors\"] = vectors\n",
        "    data[\"vectors\"] = data[\"vectors\"].apply(lambda emb: np.array(emb))\n",
        "    data[\"vectors\"] = data[\"vectors\"].apply(lambda emb: emb.reshape(1, -1))\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUxQPOuklxtq"
      },
      "outputs": [],
      "source": [
        "vector_index = create_vector_index(source_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}